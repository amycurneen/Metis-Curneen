{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Water Pump Clasificaiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from os import system\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import division\n",
    "pd.set_option('display.width',5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import patsy\n",
    "\n",
    "from sklearn import linear_model as lm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system('say I am Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import - Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is part of the Data Driven Competition\n",
    "\n",
    "https://www.drivendata.org/competitions/7/pump-it-up-data-mining-the-water-table/page/23/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Values' provided for each pump location - features\n",
    "\n",
    "df_values = pd.read_csv('/Users/amycurneen/ds/metis/metisgh/Metis-Curneen/3 - Water Pumps/Data Downloads/Training set values.csv')\n",
    "df_values.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Labels' provided for each pump location - clasificaiton - what I am predicting\n",
    "\n",
    "df_labels = pd.read_csv('/Users/amycurneen/ds/metis/metisgh/Metis-Curneen/3 - Water Pumps/Data Downloads/Training set labels.csv')\n",
    "df_labels.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import - Challenge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Values' provided for each competition pump location - features\n",
    "\n",
    "df_test_values = pd.read_csv('/Users/amycurneen/ds/metis/metisgh/Metis-Curneen/3 - Water Pumps/Data Downloads/Test set values.csv')\n",
    "df_test_values.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Labels' I will provide for each pump location - clasificaiton\n",
    "\n",
    "df_sub = pd.read_csv('/Users/amycurneen/ds/metis/metisgh/Metis-Curneen/3 - Water Pumps/Data Downloads/SubmissionFormat.csv')\n",
    "df_sub = df_sub.drop('status_group', axis = 1)\n",
    "df_sub.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My goal is to predict the operating condition of a waterpoint for each record in the dataset. I was provided the following set of information about the waterpoints:\n",
    "\n",
    "* amount_tsh - Total static head (amount water available to waterpoint)\n",
    "    * 98 unique\n",
    "* date_recorded - The date the row was entered\n",
    "    * 365 unique\n",
    "    * year - month - day\n",
    "* funder - Who funded the well\n",
    "    * 1897 unique\n",
    "    * look at top ones?\n",
    "* installer - Organization that installed the well\n",
    "    * 2145 unique\n",
    "    * DWE is main one - 10x closest other, 17k\n",
    "* wpt_name - Name of the waterpoint if there is one\n",
    "    * 37400 unique\n",
    "    * look at top ones?\n",
    "* num_private - (NO PROVIDED DESC)\n",
    "    * 65 unique\n",
    "    * USELESS FEATURE\n",
    "* population - Population around the well\n",
    "    * 1049 unique\n",
    "    * a lot are zero\n",
    "* public_meeting - True/False\n",
    "    * 2 unique\n",
    "* recorded_by - Group entering this row of data\n",
    "    * 1 unique\n",
    "    * all the same - USELESS FEATURE\n",
    "* scheme_management - Who operates the waterpoint\n",
    "    * 12 unique\n",
    "* scheme_name - Who operates the waterpoint\n",
    "    * 2696 unique\n",
    "    * USELESS FEATURE\n",
    "* permit - If the waterpoint is permitted\n",
    "    * 2 unique\n",
    "* construction_year - Year the waterpoint was constructed\n",
    "    * 55 unique\n",
    "    * third are 0 - USELESS FEATURE\n",
    "    \n",
    "\n",
    "* Geography\n",
    "    * gps_height - Altitude of the well\n",
    "        * numerical\n",
    "    * longitude - GPS coordinate\n",
    "        * numerical\n",
    "    * latitude - GPS coordinate\n",
    "        * numerical\n",
    "    * basin - Geographic water basin\n",
    "        * 9 unique\n",
    "    * subvillage - Geographic location\n",
    "        * 19287 unique\n",
    "    * region - Geographic location\n",
    "        * 21 unique\n",
    "    * region_code - Geographic location (coded)\n",
    "        * 27 unique\n",
    "    * district_code - Geographic location (coded)\n",
    "        * 20 unique\n",
    "    * lga - Geographic location\n",
    "        * 125 unique\n",
    "    * ward - Geographic location\n",
    "        * 2092 unique\n",
    "\n",
    "\n",
    "* Extraction\n",
    "    * extraction_type - The kind of extraction the waterpoint uses\n",
    "        * 18 unique\n",
    "        * Most descriptive of extraction\n",
    "    * extraction_type_group - The kind of extraction the waterpoint uses\n",
    "        * 13 unique\n",
    "        * Parent of extraction_type\n",
    "    * extraction_type_class - The kind of extraction the waterpoint uses\n",
    "        * 7 unique\n",
    "        * Parent of extraction_type_group\n",
    "\n",
    "\n",
    "* Overhead\n",
    "    * management - How the waterpoint is managed\n",
    "        * 12 unique\n",
    "    * management_group - How the waterpoint is managed\n",
    "        * 5 unique\n",
    "    * payment - What the water costs\n",
    "        * 7 unique\n",
    "        * same as payment type\n",
    "    * payment_type - What the water costs\n",
    "        * 7 unique\n",
    "        * same as payment\n",
    "\n",
    "\n",
    "* Water\n",
    "    * water_quality - The quality of the water \n",
    "        * 3 unique\n",
    "        * Subset of quality_group\n",
    "    * quality_group - The quality of the water\n",
    "        * 6 unique\n",
    "        * Parent group of water_quality\n",
    "    * quantity - The quantity of water\n",
    "        * 5 unique\n",
    "        * Same as quantity_group\n",
    "    * quantity_group - The quantity of water\n",
    "        * 5 unique\n",
    "        * Same as quantity\n",
    "    * source - The source of the water\n",
    "        * 10 unique\n",
    "    * source_type - The source of the water\n",
    "        * 7 unique\n",
    "        * Subset of source\n",
    "    * source_class - The source of the water\n",
    "        * 3 unique\n",
    "        * Subset of source_type\n",
    "    * waterpoint_type - The kind of waterpoint\n",
    "        * 6 unique\n",
    "        * Parent of waterpoint_type_group\n",
    "    * waterpoint_type_group - The kind of waterpoint\n",
    "        * 7 unique\n",
    "        * Subset of waterpoint_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myregions = list(df_values.region.unique())\n",
    "myregions.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values.region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment = list(df_values.payment.unique())\n",
    "payment.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = list(df_values.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless = ['id','date_recorded','num_private','recorded_by','scheme_name','construction_year','subvillage','ward',\n",
    "          'payment_type','quantity_group','wpt_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets_to_go = ['quality_group','extraction_type_group','extraction_type','source','source_type', \n",
    "                 'waterpoint_type_group','management']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['amount_tsh','population','latitude','longitude','gps_height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numerical = list(set(total) - set(useless) - set(subsets_to_go) - set(numerical))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_features = numerical+non_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of features that dont show often\n",
    "\n",
    "map_funder = df_values.funder.value_counts().to_dict()\n",
    "for i in range(len(map_funder.keys())):\n",
    "    keys = list(map_funder.keys())\n",
    "    a = keys[i]\n",
    "    if map_funder[a] > 800:\n",
    "        map_funder[a] = a\n",
    "    else:\n",
    "        map_funder[a] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values['funder'].replace(map_funder, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of features that dont show often\n",
    "\n",
    "map_installer = df_values.installer.value_counts().to_dict()\n",
    "for i in range(len(map_installer.keys())):\n",
    "    keys = list(map_installer.keys())\n",
    "    a = keys[i]\n",
    "    if map_installer[a] > 800:\n",
    "        map_installer[a] = a\n",
    "    else:\n",
    "        map_installer[a] = 'other'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values['installer'].replace(map_installer, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_values = df_values.fillna('other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup chalange data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funder_list = list(set(map_funder.values()))\n",
    "funder_list.remove('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installer_list = list(set(map_installer.values()))\n",
    "installer_list.remove('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_test_values.funder)):\n",
    "    if df_test_values.funder[i] not in funder_list:\n",
    "        df_test_values.at[i, 'funder'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_test_values.funder)):\n",
    "    if df_test_values.installer[i] not in funder_list:\n",
    "        df_test_values.at[i, 'installer'] = 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_values = df_test_values.fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test_values[my_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test2 = df_test_values[my_features2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create selected feature DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize data\n",
    "# df_lables, df_values - combine and shuffle this data\n",
    "\n",
    "df = pd.merge(df_labels,df_values,how = 'left')\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_features.insert(0,'status_group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df[my_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_status_group = {'functional':0,'functional needs repair':1,'non functional':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn y into 3 class 0,1,2\n",
    "df_features['status_group'].replace(map_status_group, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_features.status_group\n",
    "X = df_features.drop('status_group', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['region_code'] = X['region_code'].astype(object)\n",
    "X['district_code'] = X['district_code'].astype(object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catboost for limited features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor, CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_indices = np.where((X_train.dtypes != np.float) & (X_train.dtypes != np.int))[0]\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=categorical_features_indices)\n",
    "model=CatBoostClassifier(depth=10, learning_rate=0.3,loss_function='MultiClass')\n",
    "\n",
    "model.fit(train_pool,eval_set=(X_test, y_test),plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2=CatBoostClassifier(depth=10, learning_rate=0.3,loss_function='Recall')\n",
    "\n",
    "# model2.fit(train_pool,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = model.get_feature_importance(train_pool)\n",
    "feature_names = X_train.columns\n",
    "for score, name in sorted(zip(feature_importances, feature_names), reverse=True):\n",
    "    print('{}: {}'.format(name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('catboost_model.dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_model('catboost_model.dump') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create decision list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = list(model.predict(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_better = []\n",
    "\n",
    "for i in range(len(answers)):\n",
    "    num = int(answers[i][0])\n",
    "    answer_better.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['status_group'] = answer_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map_status_group = {v: k for k, v in map_status_group.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn y into 3 class 0,1,2\n",
    "df_sub['status_group'].replace(inv_map_status_group, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv('./Submissions/decisionTree5_10_215pm.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "columns = list(feature_sel.columns)\n",
    "feature_sel[columns[5:]] = feature_sel[columns[5:]].astype(int)\n",
    "feature_sel[columns[0]] = feature_sel[columns[0]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "feature_sel = feature_sel.sample(frac=1).reset_index(drop=True)\n",
    "y = feature_sel.status_group\n",
    "X = feature_sel.drop('status_group', axis=1)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Adjust competition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_test_values = df_test_values[['gps_height', 'longitude', 'latitude', 'basin',\n",
    "                  'extraction_type_class','payment','quantity','water_quality', 'source_class',\n",
    "                  'waterpoint_type_group','population','public_meeting','scheme_management']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# rearange columns\n",
    "cols = df_test_values.columns.tolist()\n",
    "cols = ['gps_height',\n",
    "             'longitude',\n",
    "             'latitude',\n",
    "             'population',\n",
    "             'basin',\n",
    "             'extraction_type_class',\n",
    "             'payment',\n",
    "             'quantity',\n",
    "             'water_quality',\n",
    "             'source_class',\n",
    "             'waterpoint_type_group',\n",
    "             'public_meeting',\n",
    "             'scheme_management']\n",
    "df_test_values = df_test_values[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = [0] * len(df_test_values['gps_height'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_test_values = pd.get_dummies(df_test_values,columns=list(df_test_values.columns[4:]))\n",
    "df_test_values.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "columns = list(feature_sel.columns)\n",
    "feature_sel[columns[5:]] = feature_sel[columns[5:]].astype(int)\n",
    "feature_sel[columns[0]] = feature_sel[columns[0]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_test_values['scheme_management_None'] = a\n",
    "df_test_values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "list(set(X_train.columns)-set(df_test_values.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##  B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import svm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Principle Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pcafeatures_train = pca.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# def plot_PCA_2D(data, target, target_names):\n",
    "#     colors = cycle(['r','g','b'])\n",
    "#     target_ids = range(len(target_names))\n",
    "#     plt.figure()\n",
    "#     for i, c, label in zip(target_ids, colors, target_names):\n",
    "#         plt.scatter(data[target == i, 0], data[target == i, 1],\n",
    "#                    c=c, label=label)\n",
    "#     plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plot_PCA_2D(pcafeatures_train, target=y_train, target_names=digits.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fitting Linear and RBF SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit linear model\n",
    "model_svm = svm.SVC(kernel='rbf',probability=False,cache_size=2000)\n",
    "model_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# predict out of sample\n",
    "y_pred = model_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check accuracy\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit rbf model\n",
    "# model_svm2 = svm.SVC(kernel='rbf', gamma = 0.001)\n",
    "# model_svm2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# predict out of sample\n",
    "y_pred2 = model_svm2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check accuracy\n",
    "accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "confusion_matrix(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Extra code from class to utilize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df.age=df.age.fillna(df.age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y,X=dmatrices('survived~ pclass +age+sibsp+parch+fare',data=df,return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate a confusion matrix plot: \n",
    "\n",
    "def plot_confusion_matrix(cm,title='Confusion matrix', cmap=plt.cm.Reds):\n",
    "    plt.imshow(cm, interpolation='nearest',cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "#Could be a typical function for classifying:\n",
    "\n",
    "def train_score(classifier,x,y):\n",
    "    xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(x, y, test_size=0.2, random_state=1234)\n",
    "    ytrain=np.ravel(ytrain)\n",
    "    clf = classifier.fit(xtrain, ytrain)\n",
    "    # accuracy for test & train:\n",
    "    train_acc=clf.score(xtrain, ytrain)\n",
    "    test_acc=clf.score(xtest,ytest)\n",
    "    print(\"Training Data Accuracy: %0.2f\" %(train_acc))\n",
    "    print(\"Test Data Accuracy:     %0.2f\" %(test_acc))\n",
    "    \n",
    "    y_true = ytest\n",
    "    y_pred = clf.predict(xtest)\n",
    "\n",
    "\n",
    "    conf = confusion_matrix(y_true, y_pred)\n",
    "    print(conf)\n",
    "\n",
    "    print ('\\n')\n",
    "    print (\"Precision:              %0.2f\" %(conf[0, 0] / (conf[0, 0] + conf[1, 0])))\n",
    "    print (\"Recall:                 %0.2f\"% (conf[0, 0] / (conf[0, 0] + conf[0, 1])))\n",
    "    \n",
    "    cm=confusion_matrix(y_true, y_pred, labels=None)\n",
    "    \n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "log_clf=LogisticRegression()\n",
    "train_score(log_clf,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# What about ROC ? \n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = cross_validation.train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "log = LogisticRegression()\n",
    "log.fit(xtrain,np.ravel(ytrain))\n",
    "y_score=log.predict_proba(xtest)[:,1]\n",
    "\n",
    "fpr, tpr,_ = roc_curve(ytest, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "# Plotting our Baseline..\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  Cost Benefit Example: \n",
    "\n",
    "We can also optimize our models based on specific costs associated with our classification errors; here we will use specific dollar amounts as weights.\n",
    "\n",
    "Let's say we were developing a classification model for Aircraft Delay prediction.  For this example let's assume that a true positive would \n",
    "lead to a cost savings of 2160 dollars, a false negative would cost us 2900 dollars a false positive would cost 750 dollars.  \n",
    "\n",
    "cb = np.array([[2160, -750.0], [-2900, 0]])  \n",
    "\n",
    "Expected_Value = #TPs(2160) - #FNs(2900) -#FPs(750)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "880px",
    "width": "333px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
